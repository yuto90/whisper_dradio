{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnetQx8wNpL7hCf+vQMeqy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuto90/whisper_gradio/blob/main/gijiroku_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCJDufyGyDYy"
      },
      "outputs": [],
      "source": [
        "# whisper用\n",
        "!pip install git+https://github.com/nyanta012/whisper -q\n",
        "# chatGPT用\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio==3.4.0"
      ],
      "metadata": {
        "id": "SxjLey-ZyKBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr \n",
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "id": "2Hnt-V3Qyl0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# 議事録ファイルを生成\n",
        "def generate_gijiroku(audio):\n",
        "    transcription_file = create_transcription_file(audio)\n",
        "    summaryfile = create_summaryfile(transcription_file)\n",
        "\n",
        "    return summaryfile\n",
        "\n",
        "# Whisperで文字起こしファイルを作成\n",
        "def create_transcription_file(audio):\n",
        "    results = model.transcribe(audio, verbose=False, language=\"ja\")\n",
        "\n",
        "    # アウトプット用ファイルを上書きモードで作成して開く\n",
        "    with open(\"transcribe.txt\", mode=\"w\") as f:\n",
        "        # 文字起こし結果を書き込み\n",
        "        for index, _dict in enumerate(results[\"segments\"]):\n",
        "            f.write(f'{_dict[\"text\"]}\\n')\n",
        "\n",
        "    # 作成したtxtファイルを返却\n",
        "    return \"transcribe.txt\"\n",
        "\n",
        "# chatGPTで要約ファイルを作成\n",
        "def create_summaryfile(transcription_file):\n",
        "    # APIキー\n",
        "    openai.api_key = \"\"\n",
        "    \n",
        "    system_template = \"\"\"会議の書き起こしが渡されます。\n",
        "    \n",
        "    この会議のサマリーをMarkdown形式で作成してください。サマリーは、以下のような形式で書いてください。\n",
        "    \n",
        "    - 会議の目的\n",
        "    - 会議の内容\n",
        "    - 会議の結果\"\"\"\n",
        "    \n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_template},\n",
        "            {\"role\": \"user\", \"content\": transcription_file}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 回答を取得\n",
        "    response_text = completion.choices[0].message.content\n",
        "    \n",
        "    # アウトプット用ファイルを上書きモードで作成して開く\n",
        "    with open(\"summary.txt\", mode=\"w\") as f:\n",
        "        # 結果をアウトプット用ファイルに書き込み\n",
        "        f.write(f'{response_text}')\n",
        "\n",
        "    # 作成したtxtファイルを返却\n",
        "    return \"summary.txt\"\n",
        "\n",
        "css = \"\"\"\n",
        "        .gradio-container {\n",
        "            font-family: 'IBM Plex Sans', sans-serif;\n",
        "        }\n",
        "        .container {\n",
        "            max-width: 730px;\n",
        "            margin: auto;\n",
        "            padding-top: 1.5rem;\n",
        "        }\n",
        "        #gallery {\n",
        "            min-height: 22rem;\n",
        "            margin-bottom: 15px;\n",
        "            margin-left: auto;\n",
        "            margin-right: auto;\n",
        "            border-bottom-right-radius: .5rem !important;\n",
        "            border-bottom-left-radius: .5rem !important;\n",
        "        }\n",
        "        #gallery>div>.h-full {\n",
        "            min-height: 20rem;\n",
        "        }\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "block = gr.Blocks(css=css)\n",
        "\n",
        "with block:   \n",
        "    gr.Markdown(\"GIZY\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row(mobile_collapse=False, equal_height=True):\n",
        "                text_button = gr.Button(\"generate summary\").style(\n",
        "                        margin=False,\n",
        "                        rounded=(True, True, True, True),\n",
        "                    )\n",
        "        audio = gr.Audio(source=\"upload\", type=\"filepath\", interactive=True)       \n",
        "        outputs = gr.File(label=\"summary text file\")\n",
        "        # ボタンを押した時の挙動\n",
        "        text_button.click(generate_gijiroku, inputs=[audio], outputs=[outputs])\n",
        "\n",
        "block.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gNdiQYGlzKB4",
        "outputId": "80a05f28-1426-4ff3-f8d1-636945604613"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://fa75471508a2b903.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://www.huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fa75471508a2b903.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118245/118245 [06:57<00:00, 283.29frames/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/routes.py\", line 275, in run_predict\n",
            "    output = await app.blocks.process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 760, in process_api\n",
            "    result = await self.call_function(fn_index, inputs, iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 671, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-14-5f6ab691b1ae>\", line 6, in generate_gijiroku\n",
            "    summaryfile = create_summaryfile(transcription_file)\n",
            "  File \"<ipython-input-14-5f6ab691b1ae>\", line 36, in create_summaryfile\n",
            "    completion = openai.ChatCompletion.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 230, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 624, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 687, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.AuthenticationError: You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f2efc33e260>,\n",
              " 'http://127.0.0.1:7861/',\n",
              " 'https://fa75471508a2b903.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}